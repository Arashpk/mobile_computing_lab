{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workshop 2: Bayesian Filters\n",
    "\n",
    "Before we start with Bayesian filters, let's make sure we are familiar with the basics of the probability theory and the Bayes' Rule.\n",
    "\n",
    "## 1. Conditional Probabilities\n",
    "\n",
    "Conditional probability is a measure of the probability of an event given that (by assumption, presumption, assertion or evidence) another event has occurred (source: <a href=\"https://en.wikipedia.org/wiki/Conditional_probability\">Wikipedia</a>).\n",
    "\n",
    "$$ P (A\\,/\\,B) = P (A\\,\\text{and}\\,B)\\;/\\;P(B) = P(B\\,/\\,A) \\cdot P(A)\\;/\\;P(B) $$\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Quiz: </b> The probability a person is 1.90 m tall is 0.05, the probability a person is Austrian and is 1.90 m tall is 0.01. What is the probability that a person is Austrian given that the person is 1.90 m tall?\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Quiz: </b> Initially the person can be anywhere. What is the probability that the person is in cell A, given that it hears WiFi A?\n",
    "\n",
    "<img src=\"img/ws2/quiz2.png\">\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "## 2. Bayesian Filters in One Slide (Discrete Case)\n",
    "\n",
    "Imagine a robot resides in a one-dimensional world with no idea where it is in this world. Since our robot is completely clueless about its location, it believes that every point in this one dimensional world is equally likely to be its current position. We can describe this mathematically by saying that the robot's probability function is uniform (the same) over the sample space. This represents the state of maximum confusion.\n",
    "\n",
    "<img src=\"img/ws2/bayesian_filter_basics.png\">\n",
    "\n",
    "Assume there are three landmarks, which are three red doors that all look alike and we can distinguish a door from a non-door area (blue). Since the robot has just sensed that it is near a door, it assigns these locations greater probability (indicated by the bumps in the graph) whereas, all of the other locations have decreased belief. This function represents another probability distribution, called the posterior belief where the function is defined after the robot's sense measurement has been taken. The posterior function is the best representation of the robot's current belief, where each bump represents the robot's evaluation of its position relative to a door.\n",
    "\n",
    "If the robot moves to the right a certain distance, we can shift the belief according to the motion. Notice that all of the bumps also shift to the right, as we would expect. What may come as a surprise, however, is that these bumps have not shifted perfectly. They have also flattened. This flattening is due to the uncertainty in robot motion: since the robot doesn't know exactly how far it has moved, its knowledge has become less precise and so the bumps have become less sharp. \n",
    "\n",
    "When we shift and flatten these bumps, we are performing a convolution. Convolution is a mathematical operation that takes two functions and measures their overlap. To be more specific, it measures the amount of overlap as you slide one function over another. For example, if two functions have zero overlap, the value of their convolution will be equal to zero. If they overlap completely, their convolution will be equal to one. As we slide between these two extreme cases, the convolution will take on values between zero and one.\n",
    "\n",
    "In our convolution, the first function is the belief function (labeled \"posterior\" above), and the second is the function which describes the distance moved, which we will address in more depth later. The result of this convolution is the shifted and flattened belief function shown below. Now, assume that after the robot moves it senses itself right next to a door again so that the measurement is the same as before. Just like after our first measurement, the sensing of a door will increase our probability function by a certain factor everywhere where there is a door. So, should we get the same posterior belief that we had after our first measurement? No! Because unlike with our first measurement, when we were in a state of maximum uncertainty, this time we have some idea of our location prior to sensing. This prior information, together with the second sensing of a door, combine to give us a new probability distribution, as shown in the bottom graph.\n",
    "\n",
    "In this graph we see a few minor bumps, but only one sharp peak. This peak corresponds to the second door. We have already explained this mathematically, but let's think intuitively about what happened. First, we saw the first door. This led us to believe that we were near some door, but we didn't know which. Then we moved and saw another door. We saw two doors in a row! So of course our probability function should have a major peak near the only location where we would expect to see two doors in a row.\n",
    "\n",
    "Let's generalize our sense-and-move model. Below, $X$ represents location and $Z$ measurements:\n",
    "\n",
    "<img src=\"img/ws2/bayesian_filter_basics2.png\">\n",
    "\n",
    "\n",
    "## Another Example\n",
    "\n",
    "### Initial Belief\n",
    "\n",
    "A robot __has a map__ of the grid below, but it doesn’t know where it is. \n",
    "<img src=\"img/ws2/bayesian_filter_step_1.png\">\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Exercise: </b> What is the initial belief?\n",
    "</div>\n",
    "\n",
    "\n",
    "### Sensing\n",
    "First let’s look at the sensing part:\n",
    "<img src=\"img/ws2/bayesian_filter_step_0.png\">\n",
    "\n",
    "<img src=\"img/ws2/bayesian_filter_step_2.png\">\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Exercise: </b> The observation z is <b style=\"color:red\">red</b>, what is the new belief?\n",
    "</div>\n",
    "\n",
    "<img src=\"img/ws2/bayesian_filter_step_4.png\">\n",
    "\n",
    "### Movement\n",
    "\n",
    "When using RF, you don’t want to see people teletransporting in your localization app. Movements models (any model) help a ton!\n",
    "\n",
    "<img src=\"img/ws2/bayesian_filter_step_5.png\">\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Exercise: </b> the robot is moving right, what is the new distribution?  \n",
    "</div>\n",
    "<img src=\"img/ws2/bayesian_filter_step_6.png\">\n",
    "\n",
    "\n",
    "<img src=\"img/ws2/bayesian_filter_step_7.png\">\n",
    "\n",
    "Congratulations you can now do discrete localization! Let's see how this can be used with phones!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Cookbook\n",
    "\n",
    "### Step 1: Get RSSI signal for each cell\n",
    "\n",
    "You have a map split into cells (the big room has two cells).\n",
    "<img src=\"img/ws2/bayesian_cookbook_map.png\">\n",
    "\n",
    "### Step 2: Process signal and get histogram\n",
    "\n",
    "Walk slowly inside each cell to gather RSS data. Collect different angles!\n",
    "\n",
    "<img src=\"img/ws2/bayesian_cookbook_1.png\" width=\"600\">\n",
    "\n",
    "Each cell has now a Probability Mass Function (PMF). The higher the difference between those in different cells the better!\n",
    "\n",
    "### Step 3: Store data for offline analysis\n",
    "\n",
    "<img src=\"img/ws2/bayesian_cookbook_2.png\" width=\"600\">\n",
    "\n",
    "Localization won't be trained on the spot:\n",
    "* Offline processing can help understand a method\n",
    "* Gather data 3 minutes per cell\n",
    "* Divide samples at random in test and training sets\n",
    "* Build Bayesian Filter in your language of choice (I suggest to use Python or Matlab), train it with training set and check accuracy with testing set.\n",
    "* Gather data at different days / times (multipath fading)\n",
    "\n",
    "We have the radio map in the phone -- now, let's localize!\n",
    "\n",
    "### Step 4: Get testing data\n",
    "\n",
    "* Start with initial belief\n",
    "* Do WiFi scan\n",
    "* Sort access points in decreasing order, based on RSSI\n",
    "* Choose highest, then second highest, ...\n",
    "\n",
    "<img src=\"img/ws2/bayesian_cookbook_3.png\">\n",
    "\n",
    "### Step 5: Apply Bayes\n",
    "\n",
    "Probability I am in cell $i$ given that I got RSSI measurement $r$ from access point $j$:\n",
    "\n",
    "<img src=\"img/ws2/bayesian_cookbook_4.png\">\n",
    "\n",
    "### Step 6: When to stop iterations?\n",
    "\n",
    "* No clear answer\n",
    "* At every step you can update prior with\n",
    "    * Data from other access points\n",
    "    * New scans\n",
    "* Stop when you\n",
    "    * Pass a threshold ($\\geq$ 95%)\n",
    "    * Reach a steady state (oscillation around a certain probability)\n",
    "\n",
    "\n",
    "### Step 7: Motion model\n",
    "* Differentiate between idle and walking (we won't run :-) )\n",
    "* Count number of steps $s$, or simply moving time $t$\n",
    "    * Autocorrelation / Fourier transform can be used for counting steps\n",
    "* For stride / time length assume uniform distribution\n",
    "    * For example between 0.5 and 1.2 meters\n",
    "* Hense given location $x$ the new location distribution is $[x-1.2m, x-0.5m] \\cup [x+0.5m, x+1.2m]$\n",
    "* We will only test on the map given above.\n",
    "\n",
    "\n",
    "### Step 8: GUI\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Remember</b>: No training on the spot! We will push \"Locate me\" until the app converges.\n",
    "</div>\n",
    "\n",
    "<img src=\"img/ws2/bayesian_cookbook_gui.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Tips and Tricks\n",
    "\n",
    "### Modeling radio maps\n",
    "* We suggest to use tables to store radio maps\n",
    "* But they have several limitations:\n",
    "    * Sampling granularity: What if you get RSSI value that is not present?\n",
    "    * Memory space: If you have N access points: 255 x C x N\n",
    "    \n",
    "<img src=\"img/ws2/bayesian_tips_1.png\" width=\"600\">\n",
    "\n",
    "If you approximate your RSS data with a Gaussian distribution:\n",
    "* Less memory space: 2 x C x N\n",
    "* More granularity: $f(x, \\mu, \\sigma) = \\frac{1}{\\sigma \\sqrt{2\\pi}} e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}$\n",
    "* Better accuracy with low amount of observations\n",
    "* Small scale fading can still bring surprising results but we will use several attempts when testing.\n",
    "\n",
    "<img src=\"img/ws2/bayesian_tips_2.png\" width=\"600\">\n",
    "\n",
    "### Modelling variance \n",
    "Check your testing phase on different days:\n",
    "* Multipath fading occurs due to small changes\n",
    "* People moving, opening / closing doors, ...\n",
    "\n",
    "<img src=\"img/ws2/bayesian_tips_3.png\" width=\"400\">\n",
    "\n",
    "### Concrete Example Guidelines\n",
    "Published in scientific literature:\n",
    "* Horus (Bayesian Grid)\n",
    "    * 100 samples per cell spaced 300ms, cell size: 1.5m or 2.0m\n",
    "    * Error: 2 meters\n",
    "    * Paper: <a href=\"http://www.cs.umd.edu/%7Emoustafa/papers/horus_usenix.pdf\"> The Horus WLAN Location Determination System</a>\n",
    "* Practical Robust Localization (Bayesian room)\n",
    "    * 60 seconds sampling per office, cell size: 2.5 x 5.0 meters (500 offices)\n",
    "    * 95% accuracy with 2 or 3 RSS measurements\n",
    "    * Paper: <a href=\"http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.80.6957&rep=rep1&type=pdf\">Practical Robust Localization Over Large-Scale 802.11 Wireless Networks</a>\n",
    "* Both methods provide few meters error for 1-minute sampling per cell\n",
    "* WiFi scans take a few seconds\n",
    "    * Dual band phones may bring new results. Extra: compare 2.4 and 5 GHZ bands?\n",
    "\n",
    "### Diminishing Returns \n",
    "More training and testing data does not necessarily mean much better results, but may mean more work, time and use of resources (memory, processor). Work hard but smart in your localization app!\n",
    "\n",
    "<img src=\"img/ws2/bayesian_tips_4.png\" width=\"600\">\n",
    "\n",
    "\n",
    "***\n",
    "# Credits\n",
    "* Marco Zuniga's <a href=\"http://studiegids.tudelft.nl/a101_displayCourse.do?course_id=40368\">\"Smart Phone Sensing\" Course at TU Delft</a>\n",
    "* Parts of this workshop are based on content from: <a href=\"https://www.udacity.com/course/cs373\">Artificial Intelligence for Robotics</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
