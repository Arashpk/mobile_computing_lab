{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workshop 3: TensorFlow - Human Activity Recognition\n",
    "\n",
    "Ever wondered how your smartphone, smartwatch or wristband knows when you’re walking, running or sitting? Well, your device probably has multiple sensors that give various information. GPS, audio (i.e. microphones), image (i.e. cameras), direction (i.e. compasses) and acceleration sensors are very common nowadays.\n",
    "\n",
    "<img src=\"https://cdn-images-1.medium.com/max/800/1*7Z9AG45pIbp_8BUT5bKzgw.png\" width=\"400\">\n",
    "\n",
    "We will use data collected from accelerometer sensors. Virtually every modern smartphone has a tri-axial accelerometer that measures acceleration in all three spatial dimensions. Additionally, accelerometers can detect device orientation.\n",
    "In this part of the series, we will train an LSTM Neural Network (implemented in TensorFlow) for Human Activity Recognition (HAR) from accelerometer data. The trained model will be exported/saved and added to an Android app. We will learn how to use it for inference from Java.\n",
    "\n",
    "* <a href=\"https://www.youtube.com/watch?v=XOEN9W05_4A\">__Video Demo__</a>\n",
    "* <a href=\"https://github.com/curiousily/TensorFlow-on-Android-for-Human-Activity-Recognition-with-LSTMs\">__Model Code__</a>\n",
    "* <a href=\"https://github.com/curiousily/TensorFlow-on-Android-for-Human-Activity-Recognition-with-LSTMs\">__Pre-trained Model__</a>\n",
    "* <a href=\"https://medium.com/@curiousily/human-activity-recognition-using-lstms-on-android-tensorflow-for-hackers-part-vi-492da5adef64\">__Model Code and Tutorial__</a>\n",
    "* <a href=\"https://github.com/curiousily/TensorFlow-on-Android-for-Human-Activity-Recognition-with-LSTMs\">__App Source Code__</a>\n",
    "\n",
    "\n",
    "\n",
    "## 1. Building / Training / Testing a Model\n",
    "\n",
    "The data set is provided by the Wireless Sensor Data Mining (WISDM) Lab and can be downloaded from <a href=\"http://www.cis.fordham.edu/wisdm/dataset.php\">here</a>. The data set contains 1,098,207 data points, each point consists of 6 attribues: user, timestamp, activity and accelerometer measurements. Class Distribution: walking: 424,400 (38.6%), jogging: 342,177 (31.2%), upstairs: 122,869 (11.2%), downstairs: 100,427 (9.1%), sitting: 59,939 (5.5%), standing: 48,395 (4.4%).\n",
    "\n",
    "You can train your model on a desktop, on a laptop, or on a server, and then use that pre-trained model on our mobile device. Alternatively, you can use an already <a href=\"https://github.com/curiousily/TensorFlow-on-Android-for-Human-Activity-Recognition-with-LSTMs\">pre-trained model</a>.\n",
    "\n",
    "\n",
    "\n",
    "## 2. Android App\n",
    "\n",
    "<a href=\"https://github.com/curiousily/TensorFlow-on-Android-for-Human-Activity-Recognition-with-LSTMs\">A sample app</a> that uses the exported model can be found on GitHub. It is heavily based on the Activity Recognition app by Aaqib Saeed (<a href=\"https://aqibsaeed.github.io/2017-05-02-deploying-tensorflow-model-andorid-device-human-activity-recognition/\">tutorial</a>, <a href=\"https://github.com/aqibsaeed/Human-Activity-Recognition-using-CNN/tree/master/ActivityRecognition\">app source code</a>).\n",
    "\n",
    "<img src=\"https://aqibsaeed.github.io/img/har_app_screenshot.png\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    "***\n",
    "## Related Examples and Useful Links\n",
    "\n",
    "* Paper: <a href=\"http://www.cis.fordham.edu/wisdm/public_files/sensorKDD-2010.pdf\">Activity Recognition using Cell Phone Accelerometers</a>, ACM SIGKDD, 2010.\n",
    "* <a href=\"https://github.com/aqibsaeed/Human-Activity-Recognition-using-CNN\">CNN for Human Activity Recognition</a>\n",
    "* <a href=\"https://github.com/guillaume-chevalier/LSTM-Human-Activity-Recognition\">LSTMs for Human Activity Recognition</a>\n",
    "\n",
    "\n",
    "***\n",
    "## Credits\n",
    "* <a href=\"https://medium.com/@curiousily/human-activity-recognition-using-lstms-on-android-tensorflow-for-hackers-part-vi-492da5adef64\">Human Activity Recognition using LSTMs on Android — TensorFlow for Hackers (Part VI)</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
