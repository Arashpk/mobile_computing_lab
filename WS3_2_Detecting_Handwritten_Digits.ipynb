{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workshop 3: TensorFlow - Detecting Handwritten Digits\n",
    "\n",
    "This is a handwritten character image (MNIST) classifier that can run on any Android device. The app stores a model  set of images (0-9) that we can cycle through and classify in order. It uses a pre-trained model to perform inference on the device. This idea can be applied to any images, both by using the camera and by pulling from the Web. We're using preloaded images so we can run the app in a simulator (no need for the device since it doesn't require a camera).\n",
    "\n",
    "* <a href=\"https://www.youtube.com/watch?v=gahi0Hjgokw\"><b>Video Demo</b></a>\n",
    "* <a href=\"https://github.com/llSourcell/A_Guide_to_Running_Tensorflow_Models_on_Android/tree/master/mnistandroid\"><b>App Source Code</b></a>\n",
    "\n",
    "<img src=\"https://github.com/llSourcell/A_Guide_to_Running_Tensorflow_Models_on_Android/raw/master/images/demo.png\" width=\"800\">\n",
    "\n",
    "This Android demo is based on Tensorflow tutorials:\n",
    "* <a href=\"https://www.tensorflow.org/versions/r0.10/tutorials/mnist/beginners/index.html\">MNIST For ML Beginners</a>\n",
    "* <a href=\"https://www.tensorflow.org/versions/r0.10/tutorials/mnist/pros/index.html\">Deep MNIST for Experts</a>\n",
    "\n",
    "\n",
    "\n",
    "## 1. Building / Training / Testing a Model\n",
    "\n",
    "### Data \n",
    "\n",
    "MNIST is a simple computer vision dataset (70'000 labeled examples). It consists of 28x28 pixel images of handwritten digits. Every MNIST data point, every image, can be thought of as an array of numbers describing how dark each pixel is. For example, we might think of 1 as something like:\n",
    "\n",
    "<img src=\"https://tensorflow.rstudio.com/tensorflow/articles/images/MNIST-Matrix.png\" width=\"600\">\n",
    "\n",
    "Since each image has 28 by 28 pixels, we get a 28x28 array. We can flatten each array into a 28âˆ—28=784\n",
    " dimensional vector. Each component of the vector is a value between zero and one describing the intensity of the pixel. Thus, we generally think of MNIST as being a collection of 784-dimensional vectors.\n",
    " \n",
    "The __y_train__ data is the associated labels for all the __x_train__ examples. Rather than storing the label as an integer, it is stored as a 1x10 binary array with the one representing the digit. This is also known as one-hot encoding. In the example below, the array represents a 7:\n",
    "\n",
    "<img src=\"https://d3ansictanv2wj.cloudfront.net/Img-1-array-b4889b9860c9e009bbd58e827a114129.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python 3.6.0\n",
    "# tensorflow 1.5.0\n",
    "# Keras 2.0.4\n",
    "\n",
    "import os\n",
    "import os.path as path\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.tools import freeze_graph\n",
    "from tensorflow.python.tools import optimize_for_inference_lib\n",
    "\n",
    "def load_data():\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "    y_train = keras.utils.to_categorical(y_train, 10)\n",
    "    y_test = keras.utils.to_categorical(y_test, 10)\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "x_train, y_train, x_test, y_test = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:13: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x118476a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def display_digit(digit, title = \"\"):\n",
    "    \"\"\"\n",
    "    graphically displays a 784x1 vector, representing a digit\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    fig = plt.imshow(digit.flatten().reshape(28,28))\n",
    "    fig.set_cmap('gray_r')\n",
    "    fig.axes.get_xaxis().set_visible(False)\n",
    "    fig.axes.get_yaxis().set_visible(False)\n",
    "    if title != \"\":\n",
    "        plt.title(\"Inferred label: \" + str(title))\n",
    "        \n",
    "digit = 129\n",
    "display_digit(x_train[digit], title = y_train[digit])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Model\n",
    "\n",
    "Read: <a href=\"https://hackernoon.com/visualizing-parts-of-convolutional-neural-networks-using-keras-and-cats-5cc01b214e59\">Visualizing parts of Convolutional Neural Networks using Keras and Cats</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=64, kernel_size=3, strides=1, \\\n",
    "            padding='same', activation='relu', \\\n",
    "            input_shape=[28, 28, 1]))\n",
    "    # 28*28*64\n",
    "    model.add(MaxPooling2D(pool_size=2, strides=2, padding='same'))\n",
    "    \n",
    "    # 14*14*64\n",
    "    model.add(Conv2D(filters=128, kernel_size=3, strides=1, \\\n",
    "            padding='same', activation='relu'))\n",
    "\n",
    "    # 14*14*128\n",
    "    model.add(MaxPooling2D(pool_size=2, strides=2, padding='same'))\n",
    "    \n",
    "    # 7*7*128\n",
    "    model.add(Conv2D(filters=256, kernel_size=3, strides=1, \\\n",
    "            padding='same', activation='relu'))\n",
    "    \n",
    "    # 7*7*256\n",
    "    model.add(MaxPooling2D(pool_size=2, strides=2, padding='same'))\n",
    "    \n",
    "    # 4*4*256\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "#     model.add(Dropout(0.5))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "model = build_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training / Testing / Validation\n",
    "\n",
    "When solving with a CPU an Optimization Problem, you Iteratively apply an Algorithm over some Input Data. In each of these iterations you usually update a Metric of your problem doing some Calculations on the Data. Now when the size of your data is large it might need a considerable amount of time to complete every iteration, and may consume a lot of resources. So sometimes you choose to apply these iterative calculations on a Portion of the Data to save time and computational resources. This portion is the batch_size and the process is called (in the Neural Network Lingo) batch data processing.\n",
    "\n",
    "In the neural network terminology:\n",
    "* one __epoch__ = one forward pass and one backward pass of all the training examples\n",
    "* __batch size__ = the number of training examples in one forward/backward pass. The higher the batch size, the more memory space you'll need.\n",
    "* number of __iterations__ = number of passes, each pass using [batch size] number of examples. To be clear, one pass = one forward pass + one backward pass (we do not count the forward pass and backward pass as two different passes).\n",
    "\n",
    "Advantages:\n",
    "* It requires less memory. Since you train network using less number of samples the overall training procedure requires less memory. It's especially important in case if you are not able to fit dataset in memory.\n",
    "* Typically networks trains faster with mini-batches. That's because we update weights after each propagation. In our example we've propagated 11 batches (10 of them had 100 samples and 1 had 50 samples) and after each of them we've updated network's parameters. If we used all samples during propagation we would make only 1 update for the network's parameter.\n",
    "\n",
    "Disadvantages:\n",
    "* The smaller the batch the less accurate estimate of the gradient. In the figure below you can see that mini-batch (green color) gradient's direction fluctuates compare to the full batch (blue color).\n",
    "\n",
    "<img src=\"https://i.stack.imgur.com/lU3sx.png\" width=\"700\">\n",
    "\n",
    "Training code below takes around 5 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 448s 7ms/step - loss: 0.6728 - acc: 0.7999 - val_loss: 0.1858 - val_acc: 0.9419\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12a80b128>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 1\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, \\\n",
    "    optimizer=keras.optimizers.Adadelta(), \\\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, \\\n",
    "    batch_size=BATCH_SIZE, \\\n",
    "    epochs=EPOCHS, \\\n",
    "    verbose=1, \\\n",
    "    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ETA = Estimated Time of Arrival <br>\n",
    "loss = Difference between prediction and true labels on train data <br>\n",
    "acc = Mean accuracy rate across all predictions on train data <br>\n",
    "val_loss = Difference between prediction and true labels on test data <br>\n",
    "val_acc = Mean accuracy rate across all predictions on test data <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export\n",
    "\n",
    "How to export my model?\n",
    "\n",
    "1. Train your model\n",
    "\n",
    "2. Keep an in memory copy of everything your model learned (like biases and weights) Example: `_w = sess.eval(w)`, where `w` was learned from training.\n",
    "\n",
    "3. Rewrite your model changing the variables for constants with value = in memory copy of learned variables. Example:\n",
    "`w_save = tf.constant(_w)`\n",
    "\n",
    "4. Also make sure to put names in the input and output of the model, this will be needed for the model later. Example:\n",
    "\n",
    "```\n",
    "x = tf.placeholder(tf.float32, [None, 1000], name='input')\n",
    "y = tf.nn.softmax(tf.matmul(x, w_save) + b_save), name='output')\n",
    "```\n",
    "\n",
    "5. Export your model with:\n",
    "```\n",
    "tf.train.write_graph(<graph>, <path for the exported model>, <name of the model>.pb, as_text=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ws3_hwd_data/mnist_convnet.chkp\n",
      "INFO:tensorflow:Froze 10 variables.\n",
      "Converted 10 variables to const ops.\n",
      "graph saved!\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = 'mnist_convnet'\n",
    "DIR_NAME = 'ws3_hwd_data/'\n",
    "\n",
    "def export_model(saver, model, input_node_names, output_node_name):\n",
    "    tf.train.write_graph(K.get_session().graph_def, DIR_NAME, \\\n",
    "        MODEL_NAME + '_graph.pbtxt')\n",
    "\n",
    "    saver.save(K.get_session(), DIR_NAME + MODEL_NAME + '.chkp')\n",
    "\n",
    "    freeze_graph.freeze_graph(DIR_NAME + MODEL_NAME + '_graph.pbtxt', None, \\\n",
    "        False, DIR_NAME + MODEL_NAME + '.chkp', output_node_name, \\\n",
    "        \"save/restore_all\", \"save/Const:0\", \\\n",
    "        DIR_NAME + 'frozen_' + MODEL_NAME + '.pb', True, \"\")\n",
    "\n",
    "    input_graph_def = tf.GraphDef()\n",
    "    with tf.gfile.Open(DIR_NAME + 'frozen_' + MODEL_NAME + '.pb', \"rb\") as f:\n",
    "        input_graph_def.ParseFromString(f.read())\n",
    "\n",
    "    output_graph_def = optimize_for_inference_lib.optimize_for_inference(\n",
    "            input_graph_def, input_node_names, [output_node_name],\n",
    "            tf.float32.as_datatype_enum)\n",
    "\n",
    "    with tf.gfile.FastGFile(DIR_NAME + 'opt_' + MODEL_NAME + '.pb', \"wb\") as f:\n",
    "        f.write(output_graph_def.SerializeToString())\n",
    "\n",
    "    print(\"graph saved!\")\n",
    "\n",
    "\n",
    "if not path.exists(DIR_NAME):\n",
    "    os.mkdir(DIR_NAME)\n",
    "\n",
    "export_model(tf.train.Saver(), model, [\"conv2d_1_input\"], \"dense_2/Softmax\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 2. Android App\n",
    "\n",
    "NDK (Native Development Kit) is a tool that allows you to program in C/C++ for Android devices. It integrates with the SDK and is used for performance-critical code. You should install NDK support in your Android Studio.\n",
    "\n",
    "* <a href=\"https://developer.android.com/ndk/downloads/\">Download and install Android NDK</a> (you may actually get an automatic invitation to install NDK from Android Studio once you try to build an app which requires its support).\n",
    "\n",
    "![alt text](https://jalammar.github.io/images/android-tensorflow-app-structure_2.png)\n",
    "\n",
    "* Examine and run on your hardware <a href=\"https://github.com/llSourcell/A_Guide_to_Running_Tensorflow_Models_on_Android/tree/master/mnistandroid\">app source code</a>\n",
    "\n",
    "Be aware that you used TensorFlow 1.5.0 to build your model and thus the version of TensorFlow used by the app must be 1.5.0 or higher. In app/build.gradle:\n",
    "\n",
    "```\n",
    "dependencies {\n",
    "    ...\n",
    "    implementation 'org.tensorflow:tensorflow-android:1.5.0'\n",
    "}\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "***\n",
    "## Related Examples and Useful Links\n",
    "\n",
    "* <a href=\"https://www.oreilly.com/learning/not-another-mnist-tutorial-with-tensorflow\">Not another MNIST tutorial with TensorFlow</a>\n",
    "\n",
    "\n",
    "***\n",
    "## Credits\n",
    "* YouTube video by Siraj Raval: <a href=\"https://www.youtube.com/watch?v=kFWKdLOxykE&feature=youtu.be\">A Guide to Running Tensorflow Models on Android</a>\n",
    "* <a href=\"https://github.com/llSourcell/A_Guide_to_Running_Tensorflow_Models_on_Android\">App source code</a> adjusted by Siraj Raval\n",
    "* Original <a href=\"https://github.com/miyosuda/TensorFlowAndroidMNIST\">app source code</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
